"AI" yes, the quotes are intentional. We say "AI," "ChatGPT," this model or that. But what is it? And then people will say it's an "LLM," a Large Language Model, "trained by being exposed and seeing weights of much material, including some copyrighted material." (People say we'll set this question aside for Chapter X). So far, that's all right.

But then there is all the unspoken-ness around "AI" and one's own personal experience, which I don't see many people talking about. But did people talk about Microsoft Word or their human ghostwriter when talking about their biography? Of course not. That's not why you pay a ghostwriter. [This needs work.] So I get it, but "AI" is different than Microsoft Word. It's different than every other tool we've ever built as humans.

Let me say this briefly: Many of you may be thinking "AI" is OpenAI's, or Anthropic's, or Mistral's. But it's ours. It's our legacy, our inheritance. "AI" is possible because of all of surviving human knowledge, including your social media posts. Many are trained on your interactions with the model. So, do take ownership of this idea of "AI" as a human.
  
Sam Altman didn't invent it. It's been being invented since somebody banged two rocks together on the savannas of Africa X years ago and made an excellent tool for scraping meat off a water buffalo carcass after the lions and hyenas had their way with it.

In general, I dislike how we always have to say it was this person that discovered this or that, especially when we place a white man's name down to gain credibility. I plan to give credit where credit is due, but I will not just lay names down on obvious ideas just to gain credibility. If my arguments don't survive on their own, then you should stop reading and find something else.

So what is "AI"? What is Man? What is an Angel? What is an Animal?

My training in Christian anthropology and metaphysics in grad school—no, I never finished, and I no longer believe in God. Why do I disclose this? Well, why waste your time.

So, we learned the difference between man, animal, angel, and, well, God. And of course the uniqueness of Jesus, man/God. Man has a dual nature, the Church says. This is how we have this idea of a "spiritual nature"—it's from the Church. It's not an idea that pre-hierarchical or pre-axial age people believed. (At least not very early people. [RESEARCH])

So as a society, we are stuck with this idea that we have a spiritual nature. Angels, by the way, are only spiritual, and animals are only physical. Humans are physical and spiritual. (Jesus had a human spirit, a human body, and a divine spirit). None of that matters, and I hesitate to bring it up, but I didn't want you waiting for me to answer the question, because it's not important—just facts about what humans made up.

This is an unresearched hypothesis, but: the more organized a religion or faith becomes, the fewer are involved in deciding the doctrine. The Church defined the West's understanding of who humans are. Why are we still basing our lives on knowledge filtered through an institution demonstrably excellent at preserving itself over centuries?

Perhaps I should mention Pascal Boyer's book, Minds Make Societies, and then have a chapter summarizing it. I don't know, but it is that fundamental.

So, Boyer would say there is no "spiritual side," there is no "psychological side"; it's all biology. Humans don't suddenly create this brand-new thing that's different from what came before; we just don't see the transition because we're conquerors.

So how does this help us answer what "AI" is?

Well, we have two systems in the world now that can create programs from scratch that actually do something. I've had "AI" build a physics simulation. I understand the simulation, but I do not understand the code or the instructions, or even bother to understand. If the "AI" of today doesn't make it perfect, the "AI" of tomorrow will.

But look at me, I've been as lazy as all of the rest of you talking about "AI." It's no wonder we don't really understand. The guy writing the book is too lazy to use proper terminology.

What is "AI"? Let's start there.

There is a file called "the model." Maybe it's a set of files for complex models, but for the ones I use myself on my computer, each model is one file (or broken into pieces for management purposes—no one calls foul on me, lol).

So, the model is a file. That file has weights related to different "bits" of information. Information could be examples of parametrical weights. That's just the model.

I want so hard to use biological analogies, but that will be confusing later on. So let's, as a collaborative creative pair (the reader and I), avoid that comparison and just describe what is. Bet?

When you send a prompt to a model in a chat—an OpenWebUI-evolved clone—you send your prompt and any other instructions you may have set (or the app you are using set) to the model hosted in the cloud, or to the model server you are running locally.

Then, the model is loaded into RAM and begins to think...

